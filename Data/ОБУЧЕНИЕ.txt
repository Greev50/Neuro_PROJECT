# Стохастический градиентный спуск
Классический и все еще предпочтительный алгоритм обучения нейронных сетей называется Стохастическим градиентным спуском (SGD).

Здесь одна строка данных предоставляется сети в качестве входных данных. 
Сеть обрабатывает входные нейроны, активируя их по мере поступления, чтобы, наконец, сгенерировать выходные значения. 
Это называется Прямым проходом (Forward Pass) по сети, тип прохода, который также используется после обучения сети для прогнозирования новых данных.

Выходные данные сети сравниваются с ожидаемыми тестовыми значениями, и таким образом вычисляется Ошибка (Error). 
Она затем распространяется обратно по сети, по одному слою за раз, и веса обновляются. 
Этот математический элемент называется Методом обратного распространения ошибки (Backpropagation).

Этот процесс повторяется для всех Наблюдений (Observation) в тренировочных данных. 
Один раунд обновления сети для всего набора обучающих данных называется Эпохой (Epoch). Сеть может быть обучена на протяжении десятков, сотен или тысяч эпох.

# Обновления весов
Веса в сети могут быть обновлены на основе ошибок, рассчитанных для каждого обучающего примера, и это называется онлайн-обучением. 
Это может привести к быстрым, но также и хаотичным изменениям в сети.

В качестве альтернативы, ошибки могут быть сохранены во всех обучающих примерах, а сеть может быть обновлена ​​в конце. 
Это называется Пакетным (Batch) обучением и часто бывает более стабильным.

Из-за величины набора данных и вычислительной эффективности, размер пакета, показываемого перед обновлением, часто сокращается до десятков или сотен примеров.

Количество обновляемых весов контролируется параметрами конфигурации, называемыми Скоростью обучения (Learning Rate). 
Он также называется размером шага и изменением веса сети для данной ошибки. Часто используются небольшие размеры веса, такие как 0.1 или 0.01. 
Уравнение обновления может быть дополнено дополнительными параметрами конфигурации:
   - Импульс (Momentum) – это термин, который включает свойства из предыдущего обновления, чтобы позволить весам изменяться в том же направлении, даже если ошибка уменьшается.
   - Снижение скорости обучения используется, чтобы сеть могла вносить бо́льшие изменения весов в начале и меньшие настройки под конец.

# Прогноз
После обучения нейронной сети ее можно использовать для прогнозирования. 
Мы можем делать прогнозы на основе Тестовых данных (Test Data), чтобы оценить навыки модели на незнакомых ей данных. 
Вы также можете развернуть такую программу и использовать для непрерывного прогнозирования.


--------------------------------------------------------------------------------------------------------------------------------------------------------
Топология сети и конечный набор весов – это все, что вам нужно сохранить для модели. 
Прогнозы выполняются путем предоставления входных данных в модель и выполнения прямого прохода, позволяющего генерировать выходные прогнозные данные.

